<html>
<head>
<title> CS585 Homework Template: HW4 Alex Wong  </title>
<style>
<!--
body{
font-family: 'Trebuchet MS', Verdana;
}
p{
font-family: 'Trebuchet MS', Times;
margin: 10px 10px 15px 20px;
}
h4{
    margin: 15px;
}
h3{
margin: 10px;
}
h2{
margin: 10px;
}
h1{
margin: 10px 0px 0px 20px;
}
div.main-body{
align:center;
margin: 30px;
}
hr{
margin:20px 0px 20px 0px;
}
.occulsion-img{
    width: 95%;
}
.img-face{
width:50%
}
.tg {
    border-collapse: collapse;
    border-spacing: 0;
}

.tg td {
    font-family: Arial, sans-serif;
    font-size: 14px;
    padding: 10px 5px;
    border-style: solid;
    border-width: 1px;
    overflow: hidden;
    word-break: normal;
    border-color: black;
}

.tg th {
    font-family: Arial, sans-serif;
    font-size: 14px;
    font-weight: normal;
    padding: 10px 5px;
    border-style: solid;
    border-width: 1px;
    overflow: hidden;
    word-break: normal;
    border-color: black;
}

.tg .tg-ted4 {
    border-color: #333333;
    text-align: center;
    vertical-align: middle;
}

-->
</style>
</head>

<body>
<center>
<a href="http://www.bu.edu"><img border="0" src="http://www.cs.bu.edu/fac/betke/images/bu-logo.gif"
width="119" height="120"></a>
</center>

<h1>Assignment 4</h1>
<p> 
CS 585 HW 4<br>
Alex Wong, Wei-Hsiang Lin and Rahul Suresh Babu<br>
March 24, 2020
</p>

<h1>Part 1</h1>
<div class="main-body">

<hr>
<h2>Problem Definition</h2>
<!-- TODO(R) -->
<p>The current problem involves the implementation of tracking algorithms. 
Specifically two datasets have been given, the bat dataset and the cell dataset. 
Multiple objects are present in each frame and have to be tracked. 
The assumptions we make are that the objects move only slightly between two frames. 
The anticipated difficulties are implementing a reliable tracking algorithm and obtaining correct segmentation data.</p>

<hr>
<h2>Method and Implementation </h2>
<h3>Multiple Object Tracking</h3>
<h4>Alpha-Beta Filtering</h4>
<!--TODO(R) - Implement an alpha-beta filter or using a third-party Kalman filter library and get good tracking results for simple situations (e.g. when objects move separately without occluding each other)-->
<p>For the tracking part, an alpha-beta tracker was implemented. The alpha beta observer is a simplified form of a linear state observer that assumes an object can be described by a model with 2 internal states. This system accounts for both process noise and measurement noise and is a lower order approximation.

The two internal states represented by the model are <b>position and velocity</b>. This tracker has a prediction phase where it predicts the position and velocity for this time step using knowledge from the previous time step. In then calculates the residual ( measurement for this time step - prediction) and uses it to update the position and the velocity weighed by the parameters  α,β  respectively.
</p>
<img src="./img/summary.png" class="img-face"/>
<p>Figure 1 : Algorithm summary</p>

<p>For our implementation the equations used were,
</p>
<img src="./img/equations.png" class="img-face"/>
<p>Figure 2 : Update equations</p>
<p>The values for α,β itself are hyperparameters. Typically, lower values of  α,β  reflect more belief on the prediction ( when there is more measurement noise ) and higher values reflect more belief on the measurement (less measurement noise).</p>

<p>All this was the alpha beta tracker for a single object. While extending to multiple objects, the main problem was data association. Also, all of the above parameters had to re-written as matrices and vectors. So all the update operations became vector operations.</p>

<!-- <p>We implemented the greedy matching algorithm where older objects with longer tracking history were matched first. The gating used was a circular gate of 50 px. This was a trade off between recall and precision.</p>
 -->
<!-- <p>The code was highly modularized and separate classes were created to perform the main tasks. The data_loader class was created to load all images, localization and segmentation maps. Different flags were provided to control what to load.</p>
 -->
<!-- <p>The bat_tracking class performed the actual bat tracking.</p>
 -->

<ul>
    <li>show_frame_wise methods(): ran the tracking. Different other helper functions were created to perform the other tasks.
    </li>
    <li>create_color_hash(): create the color hash to plot the tracks of the different bats.</li>
    <li>draw_line(): drew the bat tracks on the image.</li>
    <li>update_velocity(): performed the velocity updates.</li>
    <li>update_coords(): performed the position updates</li>
    <li>subtract(): calculate the residual vector</li>
    <li>association(): performed the data association</li>
    <li>distance(): calculated the euclidean distance between two points</li>
    <li>get_x_pred(): predicted the object coordinates of the next time step.</li>
</ul>

<h4>Suboptimal Bipartite Matching Algorithm - Improving Greedy Algorithm</h4>
<!-- TODO(R) - Implement a greedy, suboptimal bipartite matching algorithm -->
<p>
    To solve the bipartite matching problem, we initially implemented greedy algorithm to solve it. However, the results were very bad; mostly because it is 'greedy'. As a result, we modified the greedy algorithm to gain better results. I will explain our modifications below:
</p>

<p>
    The traditional bipartite matching problem is - <b>how can we match 2 sets of data together?</b>; in this case, the group of localization points at each frame and the group of objects that are already recognized. Using the greedy algorithm, older objects wiht longer tracking history were matched first. The gating used was a circular gate of 50 px. This was a trade off between recall and precision.
</p>

<p>
    The main problem with the greedy algorithm was most bats (and cells) stay from the first frame onwards, and therefore, there were <b><u>many objects that had the longest tracking history possible</u></b>. As a result, the greedy algorithm was not effective in this bat (and cell) dataset because the greedy algorithm tries to match the localization points and objects in a 'greedy' manner. This is very not effective in a bipartite matching algorithm because there might be <b><u>better matches along the way, but it not looked at yet (because it is greedy)</u></b>. 
</p>

<p>
    To solve the problem mentioned above, we implemented a slightly different version of the greedy algorithm. First, <b><u>every localization point picks the closest (as in predicted position) object.</u></b> Note that the distance between two objects needs to be less than the <b><u>gating</u></b> value (manually defined) in order for the pick to be valid. As you can imagine, it's possible for 2 localization points to pick the same object. In that case, we enforce a <b><u>1 to 1 mapping</u></b> by keeping only the pair of localization point and object with closest distance. The rest of the points are now turned into "zombies". Then, we repeat the localization matching and 1 to 1 mapping step again so the zombies are mapped to localization points as much as possible. Lastly, <b><u>zombies are converted into new objects.</u></b>
</p>

<h4>Handle localization errors - Half Dead</h4>

<p>
    This part tries the fix a problem the object is there but the <b><u>localization point might be missing in a few frames</u></b>. In the normal case, the localization of that object will be assigned a new object id because it is considered a new, thus different, object now. We do not want this behavior. We want the algorithm to be able to recognize that this supposedly new object is the same as the previous object. To fix this, our algorithm implements a concept we term <b><u>"Half Dead"</u></b>.
</p>

<p>
    Half Dead are unmatched objects by the end of the association method. They are 'half dead' because we don't want to discard them yet. We want to see if we can match them in the next n frames. n is a tunable variable; currently set to 5.
</p>

<h3>Segmentation/Localization</h3>
<h4>Cell Dataset</h4>
<!-- TODO(S) 
 - For cell dataset, implement a segmentation or detection algorithm to locate each cell.
 - Bonus: 1) detecting the birth of a new cell. 2) detecting migrating cells (i.e cells with filopodia). 3) handling the spurious detections (false positives). 4)trying different kinematic models. 
 - What are the advantages and drawbacks of different kinematic models: Do you need to model the velocity of the objects, or is it sufficient to just consider the distances between the objects in subsequent frames?
-->
<p>>>Type Here<<</p>

<hr>
<h2>Experiments</h2>
<!-- TODO(S) -->
<p>>>Type Here<<</p>

<hr>
<h2>Results</h2>
<!-- TODO(A) 
Display the results of your tracking algorithm on top of the original images. Use different colors to show that you successfully maintain track identity. Draw lines to show the history of the flight trajectories.
Show your tracking results on some portion of the sequence. In addition to showing your tracking results on an easy portion of the data, identify a challenging situation where your tracker succeeds, and a challenging situation where your tracker fails.
-->
<!--TODO(A)
    - Display the tracking results on top of the original images. Use different colors to show that you successfully maintain track identity. Draw lines to show the history of the flight trajectories
    - Challenge 1: Proper handling of situations when objects touch and occlude each other
    - Challenge 2: Proper handling of the beginning of new tracks and the termination of old tracks as the objects enter and leave the field of view
How do you decide to begin new tracks and terminate old tracks as the objects enter and leave the field of view?
What happens with your algorithm when objects touch and occlude each other, and how could you handle this so you do not break track?
What happens when there are spurious detections that do not connect with other measurements in subsequent frames?
-->

<h3>Handling Missing Localization Points</h3>
<table>
    <tr>
        <td style="width:25%"><img class="occulsion-img" src="./img/handle_localization_error_1.png"/></td>
        <td style="width:25%"><img class="occulsion-img" src="./img/handle_localization_error_2.png"/></td>
        <td style="width:25%"><img class="occulsion-img" src="./img/handle_localization_error_3.png"/></td>
    </tr>
    <tr>
        <td>frame n+1</td>
        <td>frame n+2 (missing localization point)</td>
        <td>frame n+3 (obj 7 is retrieved)</td>
    </tr>
</table>
<caption>Table 1. Frames to show how the association algorithm takes in account of missing localization points in some frames.</caption>

<p>As shown in Table 1, we see that in frame n+2, there is a localization error where the localization point for object 7 is not recognized. In order to handle this situation, we implemented the concept of "Half Dead" (explained earlier) to take in account of localization error in a given number of frames to handle situations like this.</p>

<h3>Removing unused object track</h3>
<table>
    <tr>
        <td style="width:33%"><img class="occulsion-img" src="./img/delete_removed_object_track_1.png"/></td>
        <td style="width:33%"><img class="occulsion-img" src="./img/delete_removed_object_track_2.png"/></td>
        <td style="width:33%"><img class="occulsion-img" src="./img/delete_removed_object_track_3.png"/></td>
    </tr>
    <tr>
        <td>frame n+1</td>
        <td>frame n+2 (missing localization point)</td>
        <td>frame n+3 (obj 7 is retrieved)</td>
    </tr>
</table>
<caption>Table 2. Frames to show that we remove unused object tracks. But we bring them back if they are recognized again in the future.</caption>

<p>Table 2 shows the same frames as Table 1. The only difference is it now shows the track of object throughout the video. Again, we see in frame n+2 that there is a missing localization point for object 7, thus, the algorithm cannot find object 7. As a result, it is considered removed and we remove the track from the current frame. In frame n+3, the missing localization point comes back and we recognize it, and therefore, we implemented a way to bring its track back and display it.</p>

<h3>Handling Objects touching and occluding</h3>
<table>
    <tr>
        <td style="width:10%"><img class="occulsion-img" src="./img/handle_occlusion_1.png"/></td>
        <td style="width:10%"><img class="occulsion-img" src="./img/handle_occlusion_2.png"/></td>
        <td style="width:10%"><img class="occulsion-img" src="./img/handle_occlusion_3.png"/></td>
        <td style="width:10%"><img class="occulsion-img" src="./img/handle_occlusion_4.png"/></td>
        <td style="width:10%"><img class="occulsion-img" src="./img/handle_occlusion_5.png"/></td>
        <td style="width:10%"><img class="occulsion-img" src="./img/handle_occlusion_6.png"/></td>
    </tr>
    <tr>
        <td>frame n+1</td>
        <td>frame n+2 (Start Occluding)</td>
        <td>frame n+3</td>
        <td>frame n+4</td>
        <td>frame n+5 (obj 52 is retrieved)</td>
        <td>frame n+6</td>
    </tr>
</table>
<caption>Table 3. Frames to show how the association algorithm handles objects that touch and occlude.</caption>

<p>As shown in Table 3, in frame n+1, we see two different objects, 65 and 52. In frames n+2 to n+4, we see that the localization algorithm interpreted the two bats occluding as 1 bat and only provided 1 localization point for it. In frame n+5, the localization point interprets two localization points for each of the two objects and we are able to interpret object 65 and 52 again using our implementation of "Half Dead".</p>

<h3>Video Result of Bat Dataset</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/6hlD6v7urvY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/npJ8O_a0Akc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h3>Video Result of Cell Dataset</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/zV1Am-DvHdY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<!-- <table>
    <tr>
        <th>Open Hand</th>
        <th>Open Hand Partial</th>
        <th>Open Fist</th>
        <th>Tumor</th>
    </tr>
    <tr>
        <td style="width:25%"><img src="./img/p1/open-bw-full.png" class="img-face"/></td>
        <td style="width:25%"><img src="./img/p1/open-bw-partial.png" class="img-face"/></td>
        <td style="width:25%"><img src="./img/p1/open_fist-bw.png" class="img-face"/></td>
        <td style="width:25%"><img src="./img/p1/tumor-fold.png" class="img-face"/></td>
    </tr>
</table> -->

<hr>
<h2>Discussion and Conclusion</h2>
<p>In this assignment, we:</p>
<ul>
    <li>Implemented Alpha Beta Tracking</li>
    <li>Improved the greedy algorithm to solve the bipartite matching problem.</li>
    <li>Implemented "Half Dead" to handle localization errors.</li>
    <li>Implemented Kalman filter and Hungarian methods.</li>
</ul>
<p>We feel that we have achieved a much better algorithm than the initial minimum viable product that we initially created. However, the implementation is not perfect and it is worth taking the time to find better ways to perform segmentation, localization and tracking because these 3 topics have a broad range of applications and is very important.</p>

</div>
</body>
</html>

